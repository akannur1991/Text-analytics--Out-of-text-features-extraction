{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from contractions import contractions_dict\n",
    "from string import punctuation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 4, 2014</td>\n",
       "      <td>A24E3SXTC62LJI</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>{'Color:': ' Bling'}</td>\n",
       "      <td>Claudia Valdivia</td>\n",
       "      <td>Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>A269FLZCB4GIPV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarah ponce</td>\n",
       "      <td>When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!</td>\n",
       "      <td>1</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2014</td>\n",
       "      <td>AB6CHQWHZW4TV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kai</td>\n",
       "      <td>so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2014</td>\n",
       "      <td>A1M117A53LEI8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sharon Williams</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.</td>\n",
       "      <td>CASE</td>\n",
       "      <td>1391472000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 3, 2014</td>\n",
       "      <td>A272DUT8M88ZS8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bella Rodriguez</td>\n",
       "      <td>I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1391385600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0  5.0      True      08 4, 2014   A24E3SXTC62LJI  7508492919   \n",
       "1  5.0      True      02 12, 2014  A269FLZCB4GIPV  7508492919   \n",
       "2  3.0      True      02 8, 2014   AB6CHQWHZW4TV   7508492919   \n",
       "3  2.0      True      02 4, 2014   A1M117A53LEI8   7508492919   \n",
       "4  4.0      True      02 3, 2014   A272DUT8M88ZS8  7508492919   \n",
       "\n",
       "                  style      reviewerName  \\\n",
       "0  {'Color:': ' Bling'}  Claudia Valdivia   \n",
       "1  NaN                   sarah ponce        \n",
       "2  NaN                   Kai                \n",
       "3  NaN                   Sharon Williams    \n",
       "4  NaN                   Bella Rodriguez    \n",
       "\n",
       "                                                                                                                                                                                                                                                                        reviewText  \\\n",
       "0  Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.   \n",
       "1  When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!                                                                                                                                                                            \n",
       "2  so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far                 \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.                                                                                                                                                                                      \n",
       "4  I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.                                                                                                                            \n",
       "\n",
       "                               summary  unixReviewTime vote image  \n",
       "0  Can't stop won't stop looking at it  1407110400      NaN  NaN   \n",
       "1  1                                    1392163200      NaN  NaN   \n",
       "2  Its okay                             1391817600      NaN  NaN   \n",
       "3  CASE                                 1391472000      NaN  NaN   \n",
       "4  Cute!                                1391385600      NaN  NaN   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('Cell_Phones_and_Accessories_5.json.gz')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall           0      \n",
       "verified          0      \n",
       "reviewTime        0      \n",
       "reviewerID        0      \n",
       "asin              0      \n",
       "style             522684 \n",
       "reviewerName      133    \n",
       "reviewText        0      \n",
       "summary           0      \n",
       "unixReviewTime    0      \n",
       "vote              1035232\n",
       "image             1100212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset = ['reviewText','summary'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    706102\n",
      "4.0    184293\n",
      "3.0    98189 \n",
      "1.0    81469 \n",
      "2.0    57153 \n",
      "Name: overall, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0    62.641789\n",
       "4.0    16.349540\n",
       "3.0    8.710830 \n",
       "1.0    7.227517 \n",
       "2.0    5.070324 \n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['overall'].value_counts())\n",
    "df['overall'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_reviews = df[df['overall']<3].iloc[:100000]\n",
    "df_positive_reviews = df[df['overall']>3].iloc[:200000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "def cleanme(txt):\n",
    "    sent = txt.lower()\n",
    "    sent_expanded_contractions = expand_contractions(sent,contractions_dict)\n",
    "    sent_expanded_contractions = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', sent_expanded_contractions)\n",
    "    sent_without_punct = strip_punctuation(sent_expanded_contractions)\n",
    "    sent_without_digits=re.sub('[0-9]+', '', sent_without_punct)\n",
    "    \n",
    "    TOKENIZER = RegexpTokenizer('(?u)\\W+|\\$[\\d\\.]+|\\S+')\n",
    "#     wrds = TOKENIZER.tokenize(sent_without_punct)\n",
    "    wrds = word_tokenize(sent_without_digits)\n",
    "    to_remove = ['no', 'not']\n",
    "    new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "    clwrds = [w for w in wrds if not w in new_stopwords]\n",
    "    ln = len(clwrds)\n",
    "    if ln>0:\n",
    "        pos = pd.DataFrame(pos_tag(wrds))\n",
    "        pos = (\" \".join(list(pos[pos[1].str.contains(\"JJ\")].iloc[:,0]))).split(\" \")\n",
    "        l2 = [\"i\",\"you\",\"me\"]\n",
    "        pos = [x for x in pos if x not in l2]\n",
    "    else:\n",
    "        pos = [\"\"]\n",
    "    rt = [ln, \" \".join(clwrds), \" \".join(pos)]\n",
    "    return(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6ffb48260a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_negative_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'reviewlen'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cleanrev'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'adjreview'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-d8f04ffddec0>\u001b[0m in \u001b[0;36mcleanme\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msent_expanded_contractions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_contractions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontractions_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msent_expanded_contractions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'(?<=[.,])(?=[^\\s])'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_expanded_contractions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0msent_without_punct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrip_punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_expanded_contractions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msent_without_digits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[0-9]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_without_punct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp = list()\n",
    "for i in range(100000):\n",
    "    tmp.append(cleanme(df_negative_reviews.iloc[i,:]['reviewText']))\n",
    "tmp = pd.DataFrame(tmp)\n",
    "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
    "\n",
    "(tmp.head())\n",
    "\n",
    "\n",
    "df_negative_reviews_new = df_negative_reviews.reset_index()\n",
    "# df_negative_reviews_new.drop(['reviewlen', 'cleanrev', 'adjreview'], axis=1, inplace=True)\n",
    "df_negative_reviews_new = pd.concat([df_negative_reviews_new,tmp], axis=1)\n",
    "df_negative_reviews_new = df_negative_reviews_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
    "df_negative_reviews_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashishkannur91\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashishkannur91\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ashishkannur91\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "txt = df_negative_reviews_new.cleanrev.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "words = nltk.tokenize.word_tokenize(txt)\n",
    "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "# stemmed_word = [snowball_stemmer.stem(word) for word in words]\n",
    "bgs = nltk.trigrams(lemmatized_word)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "fdist.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
